{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a1cf5d-22dd-4af9-8217-6a5854c85b8a",
   "metadata": {},
   "source": [
    "## 4.Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a13274-6ce0-4a70-af2a-128c9e13ed15",
   "metadata": {},
   "source": [
    "This stage we apply the model on the dataset prepared on the last stage. First, we will make a simple baseline. The test data set doesn't have a target to check, we will utilize cross-validation on the training set for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd0993-d145-415b-8b0b-ef258e3b6fb6",
   "metadata": {},
   "source": [
    "A)Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5bab9e-6735-488d-9e50-5cdf1ffd5af7",
   "metadata": {},
   "source": [
    "For the baseline we will use the logistic regression and the cross-validation on the training set. At the end we also will submit the results on the kaggle with the test set. Let's start loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a937deed-ef4b-4881-aa79-fbaaf3e06100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 04:37:48.482314: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 04:37:49.166698: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b041ea-4901-47e4-a564-9a0343fbe9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = \"../data\"\n",
    "#Loading the data\n",
    "y_train = pd.read_csv(f\"{data_path}/originalSet/train_labels.csv\")\n",
    "x_train = pd.read_parquet(f\"{data_path}/V1Set/train/\")\n",
    "#x_test = dd.read_parquet(f\"{data_path}/V1Set/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11648589-daed-41d1-a4b9-e183bb1da589",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.merge(y_train, right_on='customer_ID', left_on='customer_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94c3c64f-6ecf-4243-a890-aacb98f5c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_parquet('./merged_train/merged_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32e4065e-0064-46b1-9e0a-a8e12ce66ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = x_train.columns[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c33ae32-3164-4c6a-9430-c33aca1531ba",
   "metadata": {},
   "source": [
    "With the data loaded we need to build a class to feed the model with the samples on a time-series way. Which means, we need to feed the model with windows of time that will shift feeding the model. The model will make a set of predictions based on a windows of consecutive samples from the data. The template of the modeling and dataset window class is extracted from the tensorflow website and can be accesed by:<link>https://www.tensorflow.org/tutorials/structured_data/time_series#split_the_data</link>\n",
    "\n",
    "The main features of the input windows are:\n",
    "\n",
    "- The width (number of time steps) of the inpyt and label windows.\n",
    "- The time offset between them.\n",
    "- Which features are used as inputs, labels, or both.\n",
    "\n",
    "After prepare the dataset, we gonna use deep learning model to solve the problem. The problem we are trying to solve, receive the months and has to predict the default or not of the customer. Then we have to choose the correct architecture to solve this kind of problem. The model receives n entries and predict one unique label, this is called multi-input single output. The right deep learning architecture to solve this is a LSTM n-by-one. \n",
    "\n",
    "Now let's customize the template from the tensorflows website to fullfill ours necessity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce26a993-cff9-4db2-b4b5-a3fd5a3fa71a",
   "metadata": {},
   "source": [
    "First we will split the train data in train, test and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bdcd37d-c1bb-41da-9eb2-ff49bc2c0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split x_train in 3 new divisions, train, test, validation.\n",
    "def get_dataset_partitions_pd(df, y_train, train_split=0.7, val_split=0.2, test_split=0.1):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "\n",
    "    #specify seed to always have the same split distribution between runs\n",
    "    customer_ids = y_train.sample(frac=1, random_state=7)['customer_ID'].values\n",
    "    #splitting\n",
    "    #train\n",
    "    train_ds = df[df['customer_ID'].isin(customer_ids[:int(train_split * len(customer_ids))])]   \n",
    "    \n",
    "    #val\n",
    "    val_ds = df[df['customer_ID'].isin(customer_ids[int(train_split * len(customer_ids)):\n",
    "                                       int(train_split * len(customer_ids))+int(val_split*len(customer_ids))])]   \n",
    "    #test\n",
    "    test_ds = df[df['customer_ID'].isin(customer_ids[int(train_split * len(customer_ids))+int(val_split*len(customer_ids)):])]\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "240b2821-47b4-4a25-b9b4-fea9d26b7ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset_partitions_pd(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28528309-16f1-456b-b6cb-69081cf8c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.drop(drop_columns ,axis=1)\n",
    "val_ds = val_ds.drop(drop_columns ,axis=1)\n",
    "test_ds = test_ds.drop(drop_columns ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ed4128c-8744-4dda-9046-b28a997792fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4c390ea-909e-4604-befd-c9daea7efec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_ID', 'S_2', 'P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'D_41', 'B_3',\n",
       "       'D_44',\n",
       "       ...\n",
       "       'D_64_O', 'D_64_R', 'D_64_U', 'D_114_0.0', 'D_114_1.0', 'D_116_0.0',\n",
       "       'D_116_1.0', 'D_120_0.0', 'D_120_1.0', 'target'],\n",
       "      dtype='object', length=163)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cec7ba9-7834-4228-9d63-6f759150231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83a97a72-262c-4c69-96a8-c145cb35b722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers per set: \n",
      " train:321239.0 \n",
      " validation:1193166 \n",
      " test:596596\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of customers per set: \\n train:{len(train_ds)/13} \\n validation:{len(val_ds)} \\n test:{len(test_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d05182dc-7bfe-4a6a-9cc4-27983b76afcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                   train_df=train_ds, val_df=val_ds, test_df=test_ds,\n",
    "                   label_columns=['target']):\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "          self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                               enumerate(train_df.columns)}\n",
    "        \n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        \n",
    "        self.total_window_size = input_width + shift\n",
    "        \n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        \n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = 13\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :-1]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "            [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "            axis=-1)\n",
    "        \n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "        \n",
    "        return inputs, labels\n",
    "    def make_dataset(self, data):\n",
    "        \n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(data=data,\n",
    "                                                          targets=None,\n",
    "                                                          sequence_length=self.total_window_size,\n",
    "                                                          sequence_stride=1,\n",
    "                                                          shuffle=False,\n",
    "                                                          batch_size=32,)\n",
    "        ds = ds.map(self.split_window)\n",
    "            \n",
    "        return ds\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "            \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8afc99e-8799-4611-9fa3-3ae2b5e81637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 13\n",
       "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
       "Label indices: 13\n",
       "Label column name(s): ['target']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = WindowGenerator(input_width=13, label_width=1, shift=0)\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1288166d-7b2c-42fe-8627-9125e65bab23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All shapes are: (batch, time, features)\n",
      "Window shape: (3, 13, 161)\n",
      "Inputs shape: (3, 13, 160)\n",
      "Labels shape: (3, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 09:42:29.862084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3103 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 980, pci bus id: 0000:65:00.0, compute capability: 5.2\n"
     ]
    }
   ],
   "source": [
    "# Stack three slices, the length of the total window.\n",
    "example_window = tf.stack([np.array(train_ds[:w1.total_window_size].astype('float32')),\n",
    "                           np.array(train_ds[130:130+w1.total_window_size].astype('float32')),\n",
    "                           np.array(train_ds[260:260+w1.total_window_size].astype('float32'))])\n",
    "\n",
    "example_inputs, example_labels = w1.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'Labels shape: {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54fcad58-6408-43b9-8607-b9fc1cef7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 2\n",
    "def compile_and_fit(model, train, val, patience=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=tf.keras.metrics.Recall(),\n",
    "                                                      patience=patience,\n",
    "                                                      mode='min')\n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),   optimizer=tf.keras.optimizers.AdamW(use_ema=True),\n",
    "                  metrics=['acc',tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "    \n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                        validation_data=window.val,verbose=1,\n",
    "                        callbacks=[early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc03ba9a-5ddd-4df6-ba42-e3f4cc3edd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 04:37:55.561380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3125 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 980, pci bus id: 0000:65:00.0, compute capability: 5.2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert str to pyarrow.lib.MemoryPool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert str to pyarrow.lib.MemoryPool"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pyarrow.lib._convert_pandas_options'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codemaster/anaconda3/envs/america-exp/lib/python3.11/site-packages/pyarrow/pandas_compat.py\", line 1168, in _table_to_blocks\n",
      "    result = pa.lib.table_to_blocks(options, block_table, categories,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: Cannot convert str to pyarrow.lib.MemoryPool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 04:38:03.386922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8904\n",
      "2023-08-24 04:38:03.451563: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fef1dedaa00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-24 04:38:03.451590: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 980, Compute Capability 5.2\n",
      "2023-08-24 04:38:03.455928: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-24 04:38:03.558890: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.3537 - acc: 0.8283 - recall_1: 0.6124 - precision: 0.6866WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 9s 4ms/step - loss: 0.3536 - acc: 0.8284 - recall_1: 0.6125 - precision: 0.6870\n",
      "Epoch 2/4\n",
      "1555/1563 [============================>.] - ETA: 0s - loss: 0.3174 - acc: 0.8487 - recall_1: 0.6920 - precision: 0.7121WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3173 - acc: 0.8489 - recall_1: 0.6922 - precision: 0.7126\n",
      "Epoch 3/4\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.3081 - acc: 0.8535 - recall_1: 0.7089 - precision: 0.7185WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3082 - acc: 0.8535 - recall_1: 0.7086 - precision: 0.7186\n",
      "Epoch 4/4\n",
      "1553/1563 [============================>.] - ETA: 0s - loss: 0.3038 - acc: 0.8558 - recall_1: 0.7124 - precision: 0.7233WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3037 - acc: 0.8559 - recall_1: 0.7126 - precision: 0.7237\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert str to pyarrow.lib.MemoryPool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert str to pyarrow.lib.MemoryPool"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pyarrow.lib._convert_pandas_options'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codemaster/anaconda3/envs/america-exp/lib/python3.11/site-packages/pyarrow/pandas_compat.py\", line 1168, in _table_to_blocks\n",
      "    result = pa.lib.table_to_blocks(options, block_table, categories,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: Cannot convert str to pyarrow.lib.MemoryPool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1555/1563 [============================>.] - ETA: 0s - loss: 0.3025 - acc: 0.8573 - recall_1: 0.7202 - precision: 0.7280WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3025 - acc: 0.8575 - recall_1: 0.7200 - precision: 0.7285\n",
      "Epoch 2/4\n",
      "1554/1563 [============================>.] - ETA: 0s - loss: 0.2999 - acc: 0.8587 - recall_1: 0.7258 - precision: 0.7295WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2999 - acc: 0.8589 - recall_1: 0.7258 - precision: 0.7297\n",
      "Epoch 3/4\n",
      "1553/1563 [============================>.] - ETA: 0s - loss: 0.2960 - acc: 0.8617 - recall_1: 0.7285 - precision: 0.7366WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2960 - acc: 0.8618 - recall_1: 0.7283 - precision: 0.7368\n",
      "Epoch 4/4\n",
      "1551/1563 [============================>.] - ETA: 0s - loss: 0.2926 - acc: 0.8642 - recall_1: 0.7324 - precision: 0.7419WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2927 - acc: 0.8643 - recall_1: 0.7322 - precision: 0.7421\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert str to pyarrow.lib.MemoryPool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert str to pyarrow.lib.MemoryPool"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pyarrow.lib._convert_pandas_options'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codemaster/anaconda3/envs/america-exp/lib/python3.11/site-packages/pyarrow/pandas_compat.py\", line 1168, in _table_to_blocks\n",
      "    result = pa.lib.table_to_blocks(options, block_table, categories,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: Cannot convert str to pyarrow.lib.MemoryPool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.2949 - acc: 0.8634 - recall_1: 0.7387 - precision: 0.7329WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2948 - acc: 0.8634 - recall_1: 0.7389 - precision: 0.7329\n",
      "Epoch 2/4\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.2927 - acc: 0.8653 - recall_1: 0.7387 - precision: 0.7385WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2927 - acc: 0.8653 - recall_1: 0.7388 - precision: 0.7384\n",
      "Epoch 3/4\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2915 - acc: 0.8633 - recall_1: 0.7358 - precision: 0.7340WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2915 - acc: 0.8633 - recall_1: 0.7358 - precision: 0.7340\n",
      "Epoch 4/4\n",
      "1554/1563 [============================>.] - ETA: 0s - loss: 0.2914 - acc: 0.8653 - recall_1: 0.7331 - precision: 0.7409WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2914 - acc: 0.8654 - recall_1: 0.7338 - precision: 0.7411\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert str to pyarrow.lib.MemoryPool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert str to pyarrow.lib.MemoryPool"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pyarrow.lib._convert_pandas_options'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codemaster/anaconda3/envs/america-exp/lib/python3.11/site-packages/pyarrow/pandas_compat.py\", line 1168, in _table_to_blocks\n",
      "    result = pa.lib.table_to_blocks(options, block_table, categories,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: Cannot convert str to pyarrow.lib.MemoryPool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.2914 - acc: 0.8650 - recall_1: 0.7271 - precision: 0.7441WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2916 - acc: 0.8649 - recall_1: 0.7270 - precision: 0.7439\n",
      "Epoch 2/4\n",
      "1554/1563 [============================>.] - ETA: 0s - loss: 0.2889 - acc: 0.8660 - recall_1: 0.7380 - precision: 0.7417WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2890 - acc: 0.8659 - recall_1: 0.7379 - precision: 0.7414\n",
      "Epoch 3/4\n",
      "1552/1563 [============================>.] - ETA: 0s - loss: 0.2877 - acc: 0.8655 - recall_1: 0.7414 - precision: 0.7389WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2875 - acc: 0.8654 - recall_1: 0.7412 - precision: 0.7384\n",
      "Epoch 4/4\n",
      "1554/1563 [============================>.] - ETA: 0s - loss: 0.2862 - acc: 0.8667 - recall_1: 0.7439 - precision: 0.7410WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2861 - acc: 0.8667 - recall_1: 0.7436 - precision: 0.7408\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert str to pyarrow.lib.MemoryPool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert str to pyarrow.lib.MemoryPool"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pyarrow.lib._convert_pandas_options'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codemaster/anaconda3/envs/america-exp/lib/python3.11/site-packages/pyarrow/pandas_compat.py\", line 1168, in _table_to_blocks\n",
      "    result = pa.lib.table_to_blocks(options, block_table, categories,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: Cannot convert str to pyarrow.lib.MemoryPool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1554/1563 [============================>.] - ETA: 0s - loss: 0.2934 - acc: 0.8632 - recall_1: 0.7334 - precision: 0.7395WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2934 - acc: 0.8631 - recall_1: 0.7337 - precision: 0.7391\n",
      "Epoch 2/4\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.2922 - acc: 0.8635 - recall_1: 0.7365 - precision: 0.7394WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2922 - acc: 0.8635 - recall_1: 0.7364 - precision: 0.7390\n",
      "Epoch 3/4\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.2922 - acc: 0.8641 - recall_1: 0.7423 - precision: 0.7381WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2922 - acc: 0.8641 - recall_1: 0.7425 - precision: 0.7378\n",
      "Epoch 4/4\n",
      "1556/1563 [============================>.] - ETA: 0s - loss: 0.2916 - acc: 0.8655 - recall_1: 0.7400 - precision: 0.7433WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2916 - acc: 0.8655 - recall_1: 0.7400 - precision: 0.7430\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert str to pyarrow.lib.MemoryPool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert str to pyarrow.lib.MemoryPool"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pyarrow.lib._convert_pandas_options'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codemaster/anaconda3/envs/america-exp/lib/python3.11/site-packages/pyarrow/pandas_compat.py\", line 1168, in _table_to_blocks\n",
      "    result = pa.lib.table_to_blocks(options, block_table, categories,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: Cannot convert str to pyarrow.lib.MemoryPool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.2881 - acc: 0.8654 - recall_1: 0.7455 - precision: 0.7364WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2882 - acc: 0.8653 - recall_1: 0.7453 - precision: 0.7361\n",
      "Epoch 2/4\n",
      "1554/1563 [============================>.] - ETA: 0s - loss: 0.2848 - acc: 0.8695 - recall_1: 0.7485 - precision: 0.7466WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2849 - acc: 0.8695 - recall_1: 0.7484 - precision: 0.7465\n",
      "Epoch 3/4\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2843 - acc: 0.8683 - recall_1: 0.7572 - precision: 0.7390WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2843 - acc: 0.8683 - recall_1: 0.7572 - precision: 0.7390\n",
      "Epoch 4/4\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.2866 - acc: 0.8679 - recall_1: 0.7413 - precision: 0.7456WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2867 - acc: 0.8679 - recall_1: 0.7412 - precision: 0.7453\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert str to pyarrow.lib.MemoryPool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert str to pyarrow.lib.MemoryPool"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pyarrow.lib._convert_pandas_options'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codemaster/anaconda3/envs/america-exp/lib/python3.11/site-packages/pyarrow/pandas_compat.py\", line 1168, in _table_to_blocks\n",
      "    result = pa.lib.table_to_blocks(options, block_table, categories,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: Cannot convert str to pyarrow.lib.MemoryPool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.2852 - acc: 0.8682 - recall_1: 0.7427 - precision: 0.7502WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2852 - acc: 0.8682 - recall_1: 0.7427 - precision: 0.7502\n",
      "Epoch 2/4\n",
      "1555/1563 [============================>.] - ETA: 0s - loss: 0.2860 - acc: 0.8674 - recall_1: 0.7466 - precision: 0.7460WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2858 - acc: 0.8675 - recall_1: 0.7466 - precision: 0.7461\n",
      "Epoch 3/4\n",
      "1552/1563 [============================>.] - ETA: 0s - loss: 0.2821 - acc: 0.8693 - recall_1: 0.7520 - precision: 0.7488WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2820 - acc: 0.8693 - recall_1: 0.7519 - precision: 0.7487\n",
      "Epoch 4/4\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2821 - acc: 0.8700 - recall_1: 0.7513 - precision: 0.7509WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2821 - acc: 0.8700 - recall_1: 0.7513 - precision: 0.7510\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert str to pyarrow.lib.MemoryPool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert str to pyarrow.lib.MemoryPool"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pyarrow.lib._convert_pandas_options'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codemaster/anaconda3/envs/america-exp/lib/python3.11/site-packages/pyarrow/pandas_compat.py\", line 1168, in _table_to_blocks\n",
      "    result = pa.lib.table_to_blocks(options, block_table, categories,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: Cannot convert str to pyarrow.lib.MemoryPool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1551/1563 [============================>.] - ETA: 0s - loss: 0.2892 - acc: 0.8650 - recall_1: 0.7417 - precision: 0.7405WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2892 - acc: 0.8649 - recall_1: 0.7414 - precision: 0.7402\n",
      "Epoch 2/4\n",
      "1556/1563 [============================>.] - ETA: 0s - loss: 0.2860 - acc: 0.8665 - recall_1: 0.7390 - precision: 0.7461WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2858 - acc: 0.8665 - recall_1: 0.7387 - precision: 0.7460\n",
      "Epoch 3/4\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.2859 - acc: 0.8677 - recall_1: 0.7399 - precision: 0.7491WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2858 - acc: 0.8677 - recall_1: 0.7399 - precision: 0.7490\n",
      "Epoch 4/4\n",
      "1555/1563 [============================>.] - ETA: 0s - loss: 0.2855 - acc: 0.8665 - recall_1: 0.7370 - precision: 0.7471WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2854 - acc: 0.8666 - recall_1: 0.7371 - precision: 0.7472\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert str to pyarrow.lib.MemoryPool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert str to pyarrow.lib.MemoryPool"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pyarrow.lib._convert_pandas_options'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codemaster/anaconda3/envs/america-exp/lib/python3.11/site-packages/pyarrow/pandas_compat.py\", line 1168, in _table_to_blocks\n",
      "    result = pa.lib.table_to_blocks(options, block_table, categories,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: Cannot convert str to pyarrow.lib.MemoryPool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1551/1563 [============================>.] - ETA: 0s - loss: 0.2844 - acc: 0.8683 - recall_1: 0.7334 - precision: 0.7496WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2843 - acc: 0.8682 - recall_1: 0.7337 - precision: 0.7491\n",
      "Epoch 2/4\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2808 - acc: 0.8690 - recall_1: 0.7513 - precision: 0.7429WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2808 - acc: 0.8690 - recall_1: 0.7513 - precision: 0.7428\n",
      "Epoch 3/4\n",
      "1554/1563 [============================>.] - ETA: 0s - loss: 0.2806 - acc: 0.8701 - recall_1: 0.7551 - precision: 0.7440WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2807 - acc: 0.8701 - recall_1: 0.7552 - precision: 0.7439\n",
      "Epoch 4/4\n",
      "1553/1563 [============================>.] - ETA: 0s - loss: 0.2796 - acc: 0.8718 - recall_1: 0.7454 - precision: 0.7537WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2796 - acc: 0.8718 - recall_1: 0.7457 - precision: 0.7535\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert str to pyarrow.lib.MemoryPool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert str to pyarrow.lib.MemoryPool"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pyarrow.lib._convert_pandas_options'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codemaster/anaconda3/envs/america-exp/lib/python3.11/site-packages/pyarrow/pandas_compat.py\", line 1168, in _table_to_blocks\n",
      "    result = pa.lib.table_to_blocks(options, block_table, categories,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: Cannot convert str to pyarrow.lib.MemoryPool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.2810 - acc: 0.8702 - recall_1: 0.7466 - precision: 0.7483WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.2811 - acc: 0.8696 - recall_1: 0.7466 - precision: 0.7460\n",
      "Epoch 2/4\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.2815 - acc: 0.8671 - recall_1: 0.7415 - precision: 0.7412WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.2811 - acc: 0.8676 - recall_1: 0.7436 - precision: 0.7416\n",
      "Epoch 3/4\n",
      "272/279 [============================>.] - ETA: 0s - loss: 0.2766 - acc: 0.8712 - recall_1: 0.7567 - precision: 0.7457WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.2761 - acc: 0.8713 - recall_1: 0.7575 - precision: 0.7455\n",
      "Epoch 4/4\n",
      "269/279 [===========================>..] - ETA: 0s - loss: 0.2770 - acc: 0.8726 - recall_1: 0.7611 - precision: 0.7479WARNING:tensorflow:Early stopping conditioned on metric `Recall(name=recall,dtype=float32,thresholds=None,top_k=None,class_id=None)` which is not available. Available metrics are: loss,acc,recall_1,precision\n",
      "279/279 [==============================] - 1s 4ms/step - loss: 0.2768 - acc: 0.8724 - recall_1: 0.7610 - precision: 0.7470\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "MAX_EPOCHS=4\n",
    "patience=2\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, dropout=0.8),\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, dropout=0.7),\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, dropout=0.6),\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False, dropout=0.5),\n",
    "    #tf.keras.layers.Flatten(),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=128, activation= tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(units=64, activation= tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(units=1, activation= tf.keras.activations.sigmoid)\n",
    "])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='recall', patience=patience, mode='min')\n",
    "lstm_model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.AdamW(use_ema=True),\n",
    "              metrics=['acc',tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "parquet_file = pq.ParquetFile('./merged_train/merged_train.parquet')\n",
    "history = []\n",
    "for me in range(MAX_EPOCHS):\n",
    "    for batch in parquet_file.iter_batches(batch_size=650000):\n",
    "        df = batch.to_pandas('./merged_train/merged_train.parquet')\n",
    "        #data = np.array(data, dtype=np.float32)\n",
    "        ds_train = tf.keras.utils.timeseries_dataset_from_array(data=df.iloc[:, 2:-1].to_numpy(),\n",
    "                                                              targets=df.iloc[:, -1].to_numpy(),\n",
    "                                                              sequence_length=13,\n",
    "                                                              sequence_stride=13,\n",
    "                                                              shuffle=False,\n",
    "                                                              batch_size=32,)\n",
    "        history.append( lstm_model.fit(ds_train, epochs=1,shuffle=False,verbose=1,\n",
    "                            callbacks=[early_stopping]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53750fea-8d28-4340-947e-13d48d99ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save_weights('lstm_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79f1e00-7971-4a9c-bb95-1a9fca86edbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "621/621 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "parquet_file = pq.ParquetFile('./unified_test/test.parquet')\n",
    "count = 0\n",
    "for batch in parquet_file.iter_batches(batch_size=130000):\n",
    "    df = batch.to_pandas()\n",
    "    customers = df['customer_ID'].copy()\n",
    "    test = pd.DataFrame(customers.unique().to_numpy().reshape((-1,1)),columns=['customer_ID'])\n",
    "    \n",
    "    #data = np.array(data, dtype=np.float32)\n",
    "    ds_test = tf.keras.utils.timeseries_dataset_from_array(data=df.iloc[:, 2:].to_numpy(),\n",
    "                                                          targets=None,\n",
    "                                                          sequence_length=13,\n",
    "                                                          sequence_stride=13,\n",
    "                                                          shuffle=False,\n",
    "                                                          batch_size=1)\n",
    "    predictions = lstm_model.predict(ds_test)\n",
    "    test['predictions'] = np.array(predictions).reshape((-1,1))\n",
    "    test['predictions'] = test['predictions'].apply(lambda x: 1 if x >=0.5 else 0)\n",
    "    test.to_parquet(f'../data/submit_data/answer{count}.parquet')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4ec33c-94e7-4c95-ad55-85af9b36b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_parquet(\"../data/submit_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b49484ce-9df4-4c14-a3f6-ad581a93ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.rename({'predictions': 'prediction'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a572e18a-0c2e-4b54-9bb2-3729a9c8ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"sub_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed86bb5d-1402-4527-8a1b-572ab8f7b041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: kaggle: command not found\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c amex-default-prediction -f 'sub_final.csv' -m \"LSTM+DENSE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1962ba5-e833-49db-900a-3e4d025e3a67",
   "metadata": {},
   "source": [
    "#### Final score:\n",
    "#### score:0.44\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
